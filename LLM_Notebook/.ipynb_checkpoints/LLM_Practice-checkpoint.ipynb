{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e9541445-ea3f-47e9-9dfc-31ff62b4144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install openai\n",
    "!pip install simplejson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5d9548da-f57a-4662-8446-2ddcb761d634",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0e5488-1b6a-49e7-b959-6913bbbad665",
   "metadata": {},
   "source": [
    "# Amazon Data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3eb55a7-25d5-4bb2-abcd-9d73b2c1fab6",
   "metadata": {},
   "source": [
    "## Data Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e3cce296-b487-4945-a8a9-a80e25398017",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"FeaturesDict({\\n    'author': string,\\n    'body': string,\\n    'content': string,\\n    'id': string,\\n    'normalizedBody': string,\\n    'subreddit': string,\\n    'subreddit_id': string,\\n    'summary': string,\\n})\""
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Dataset format\n",
    "\"\"\"FeaturesDict({\n",
    "    'author': string,\n",
    "    'body': string,\n",
    "    'content': string,\n",
    "    'id': string,\n",
    "    'normalizedBody': string,\n",
    "    'subreddit': string,\n",
    "    'subreddit_id': string,\n",
    "    'summary': string,\n",
    "})\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "53b5262b-f408-43f3-91fe-c7d7cb8cb6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_file = (\"Watches.txt.gz\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "9e47c1e1-9789-497f-bc90-efde4acbcf08",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "IOPub data rate exceeded.\n",
      "The Jupyter server will temporarily stop sending output\n",
      "to the client in order to avoid crashing it.\n",
      "To change this limit, set the config variable\n",
      "`--ServerApp.iopub_data_rate_limit`.\n",
      "\n",
      "Current values:\n",
      "ServerApp.iopub_data_rate_limit=1000000.0 (bytes/sec)\n",
      "ServerApp.rate_limit_window=3.0 (secs)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "def parse_file_to_json(file_path):\n",
    "    entries = []  # List to hold all entries\n",
    "    current_entry = {}  # Dictionary to hold the current entry being processed\n",
    "    \n",
    "    with open(file_path, 'r') as file:\n",
    "        for line in file:\n",
    "            # Check if line is not just a newline character, indicating the start of a new entry or continuation of current\n",
    "            if line.strip():\n",
    "                # Split the line into key and value\n",
    "                key, value = line.split(\": \", 1)\n",
    "                # Adjusting for keys that contain '/'\n",
    "                formatted_key = key.replace(\"/\", \"_\")\n",
    "                current_entry[formatted_key] = value.strip()\n",
    "            else:\n",
    "                # If there's an empty line, it means the previous entry has ended (if there was one)\n",
    "                if current_entry:\n",
    "                    entries.append(current_entry)\n",
    "                    current_entry = {}  # Reset for the next entry\n",
    "        \n",
    "        # After the loop ends, check if there's an entry that hasn't been added to the list\n",
    "        if current_entry:\n",
    "            entries.append(current_entry)\n",
    "    \n",
    "    # Convert the list of dictionaries to JSON\n",
    "    json_data = json.dumps(entries, indent=4)\n",
    "    \n",
    "    return json_data\n",
    "\n",
    "# Replace 'your_file_path_here.txt' with the path to your actual file\n",
    "file_path = 'Watches.txt'\n",
    "json_output = parse_file_to_json(file_path)\n",
    "print(json_output)\n",
    "\n",
    "# Optionally, you can write the JSON data to a file\n",
    "with open('output.json', 'w') as json_file:\n",
    "    json_file.write(json_output)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef8c12c6-baf0-4dfc-ac29-9d62eafbb656",
   "metadata": {},
   "source": [
    "## LLM Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2fae2fe0-8e77-4eb6-82d5-d0a3f50f1486",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_message = \"You are a sentiment analyzer. Your missions is to read through a list of amazon reviews for a specific product and summarize the key aspect of significant reviews. It is crucial the you weigh the importance of the review by how meaningful they are and how relevant the review is to the product. You are to look at one review at a time and evalute the significance of each. Then, from your evalutation, combine these reviews based on the weights you found. This resulting compilation should be a list of good and bad parts of all the reviews overall.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "452030b1-1432-4063-923b-2177b475f109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Once a lonely man lived in a rustic house. He treasured an old violin. Every night heâ€™d play, casting magical notes into the air. Locals whispered of a ghost violinist. One night, the violin fell silent. The house remained vacant for years. A girl discovered the dusty violin years later; her fingers coaxed sweet melodies from it. The locals smiled at the ghost violinist's return."
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "stream = client.chat.completions.create(\n",
    "    model=\"gpt-4\",\n",
    "    messages=[{\n",
    "        \"role\": \"system\", \"content\": system_message,\n",
    "        \"role\": \"user\", \"content\": \"Tell me a 100 word story.\",\n",
    "    }],\n",
    "    stream=True,\n",
    ")\n",
    "for chunk in stream:\n",
    "    if chunk.choices[0].delta.content is not None:\n",
    "        print(chunk.choices[0].delta.content, end=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa43d1c6-19d3-44fd-a9fd-7aadd10d511e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
